<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<html>

<head>
<title>Ruogu Fang</title>
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<style>

<!-- Page Format -->
A {	TEXT-DECORATION: none}
A:hover {	TEXT-DECORATION: underline}
#uvacshome-header {	PADDING-RIGHT: 5px; BORDER-BOTTOM: #00599c 2px solid; FONT-FAMILY: Verdana}
#uvacshome-footer {	BORDER-TOP: #ccc 2px solid; FONT-SIZE: 9px; FONT-FAMILY: Verdana}
#uvacshome-footer-table {	PADDING-RIGHT: 5px; BORDER-TOP: #000000 1px solid; PADDING-LEFT: 5px; FONT-SIZE: 9px; PADDING-BOTTOM: 0px; MARGIN: 0px; COLOR: #666666; PADDING-TOP: 0px}
#uvacshome-searchbox {	PADDING-RIGHT: 0px; PADDING-LEFT: 0px; FONT-SIZE: 11px; PADDING-BOTTOM: 0px; MARGIN: 0px; WIDTH: 135px; PADDING-TOP: 0px; FONT-FAMILY: Verdana; HEIGHT: 19px}
#uvacshome-searchbutton {	PADDING-RIGHT: 0px; PADDING-LEFT: 0px; FONT-SIZE: 11px; PADDING-BOTTOM: 0px; WIDTH: 60px; PADDING-TOP: 0px; FONT-FAMILY: Verdana}
#uvacshome-searchlinks {	PADDING-RIGHT: 5px; FONT-SIZE: 10px; FONT-FAMILY: Verdana; TEXT-ALIGN: right}


<!-- Fonts -->
H1 {	FONT-SIZE: 28px; COLOR: darkblue; FONT-FAMILY: Arial, helvetica, sans-serif}
H2 {	FONT-SIZE: 22px; COLOR: darkblue; FONT-FAMILY: Arial, helvetica, sans-serif}
H3 {	FONT-SIZE: 18px; COLOR: darkblue; FONT-FAMILY: Arial, helvetica, sans-serif; BACKGROUND: #ddeef0; padding-top:5px; padding-bottom:5px; padding-left:10px}
H4 {	FONT-SIZE: 12px; COLOR: darkblue; FONT-FAMILY: Arial, helvetica, sans-serif; top-padding: .2em}
H5 {	COLOR: darkblue; FONT-FAMILY: Arial, helvetica, sans-serif; top-padding: .2em}
TITLE {	COLOR: darkblue; FONT-FAMILY: Arial, helvetica, sans-serif}
A:link {	COLOR: blue}
A:visited {	COLOR: #990099}
A:active {	COLOR: green}
A:hover {	COLOR: red}
BODY {	MARGIN: 2% 8%}
H4 {	MARGIN-LEFT: 0%; MARGIN-RIGHT: 0%}
H3 {	MARGIN-LEFT: 0%; MARGIN-RIGHT: 0%}
H2 {	MARGIN-LEFT: 0%; MARGIN-RIGHT: 0%}
H1 {	MARGIN-LEFT: 0%; MARGIN-RIGHT: 0%}
.style2 {font-family: "Times New Roman", Times, serif}
.style3 {font-family: "Times New Roman", Times, serif; font-size: 18px; }
.style6 {font-size: 18px}
.style10 {color: darkblue; }
.style14 {font-family: "Times New Roman", Times, serif; font-size: 24px; }
.style16 {font-family: Arial, Helvetica, sans-serif}
.style26 {color: #0066CC}
.style32 {color: #003366}
.style33 {font-family: "Times New Roman", Times, serif; font-size: 17px; }
.style34 {
	font-family: "Times New Roman", Times, serif;
	font-size: 18px;
	font-weight: bold;
	color: #000000;
}
.style35 {
	color: red;
	font-weight: bold;
}
.style36 {color: #FF0000}
.style38 {
	font-family: "Times New Roman", Times, serif;
	font-size: 18px;
	color: #990066;
	font-weight: bold;
}
.style42 {
	font-size: 20px;
	font-weight: bold;
}
.style46 {font-family: "Times New Roman", Times, serif; font-size: 20px; }
.style47 {font-size: 18px; color: #000000; font-family: "Times New Roman", Times, serif;}
.style48 {color: #000000}
.style50 {font-family: "Times New Roman", Times, serif; color: #000000;}
.style52 {font-weight: bold; color: #000000; font-family: "Times New Roman", Times, serif;}
.style56 {
	font-family: "Times New Roman", Times, serif;
	font-size: 20px;
	color: #330099;
}
.style49 {color: #FF00FF}
</style>
<!-- End Setup-->

<meta content="Microsoft FrontPage 3.0" name="GENERATOR">


<!-- Start Material -->
</head>

<body bgColor="#ffffff">

<p align="center"><img height="237" alt hspace="9" src="NSF_4-Color_bitmap_Logo.png" width="244"
align="left" border="0"> </p>

<hr noShade SIZE="3">
<p class="style14"><span class="style14">IIS-1908299 III: Small: Collaborative Research: </span></p>
<p class="style42"><span class="style14">Modeling Multi-Level Connectivity of Brain Dynamics</span></p>

<p><span class="style46"><span class="style16"><span class="style42">PIs: <a href="https://www.bme.ufl.edu/labs/fang/ruogu/index.html">Prof. Ruogu Fang</a> and <a href="https://www.bme.ufl.edu/dept-member/ding_mingzhou/"> Prof. Mingzhou Ding</a> </span></span></span></p>

<p><span class="style14">University of Florida</span></p>
<hr noShade SIZE="3">
<span class="style2"><span class="style6"><span class="style16"><span class="style2"><st1:City w:st="on"><st1:PlaceName w:st="on"></st1:PlaceName></st1:City></span></span></span></span>
<p class="style3"><img src="uf-logo.png" width="482" height="95"></p>


<!--Project Summary-->
<h3>Project Summary </h3>

<p class="style38">
The temporal dynamics of blood flows through the network of cerebral arteries and veins provides a window into the health of the human brain. Since the brain is vulnerable to disrupted blood supply, brain dynamics serves as a crucial indicator for many kinds of neurological diseases such as stroke, brain cancer, and Alzheimer's disease. Existing efforts at characterizing brain dynamics have predominantly centered on 'isolated' models in which data from single-voxel, single-modality, and single-subject are characterized. However, the brain is a vast network, naturally connected on structural and functional levels, and multimodal imaging provides complementary information on this natural connectivity. Thus, the current isolated models are deemed not capable of offering the platform necessary to enable many of the potential advancements in understanding, diagnosing, and treating neurological and cognitive diseases, leaving a critical gap between the current computational modeling capabilities and the needs in brain dynamics analysis. This project aims to bridge this gap by exploiting multi-scale structural (voxel, vasculature, tissue) connectivity and multi-modal (anatomical, angiography, perfusion) connectivity to develop an integrated connective computational paradigm for characterizing and understanding brain dynamics.
</p>

<p class="style38">
The approach consists of three thrusts: (1) multi-scale structural connectivity modeling to quantify brain dynamics beyond a single voxel; (2) multimodal dynamic dictionary learning for mining hidden complementary information; and (3) multicenter evaluation to assess the efficacy of the proposed models at three nationally renowned healthcare systems. Successful project completion would potentially transform the rapidly evolving field of brain dynamics modeling, facilitate basic neuroscience discovery and enable comprehensive identification of neurovascular diseases. Aiming to broaden its impact this project will also implement educational initiatives to expose students, middle school teachers, and medical professionals to 'CS for All,' to foster interests in STEM and cross-disciplinary careers, and to promote research on the convergence of computer science and computational thinking for brain health and neuromedicine.
</p>

<!--Project Publications-->
<h3>Project Publications</h3>
<p class="style3"><span class="style35">[Nature SR'21]</span> Jianqiao Tian*, Glenn Smith, Han Guo, Boya Liu, Zehua Pan, Zijie Wang, Shuangyu Xiong, Ruogu Fang: Modular machine learning for Alzheimer's disease classification from retinal vasculature. <i>Nature Scientific Reports</i>, 2021. </p>
<p class="style3"><span class="style35">[BS'20]</span> Alejandro Albizu, Ruogu Fang, Aprinda Indahlastari, Andrew OShea, Skylar E. Stolte*, Kyle B. See*, Emanuel M. Boutzoukas, Jessica N. Kraft, Nicole R. Nissim and Adam J. Woods: Machine learning and individual variability in electric field characteristics predict tDCS treatment response. <i>Brain Stimulation</i>, 2020. </p>
<p class="style3"><span class="style35">[NTS'20]</span> Albizu A, Fang R, Indahlastari A, Nissim NR, OShea A, Woods AJ: Determinants of Treatment Response to Transcranial Direct Current Stimulation. <i>5th Annual NYC Neuromodulation Conference</i>, April 20-22, 2020. <span class="style38">Outstanding Presentation by Early Career Scientist Award</span></p>
<p class="style3"><span class="style35">[INS'20]</span> Albizu A, Indahlastari A, Nissim NR, OShea A, Ruogu Fang, Woods AJ: Building Personalized Medicine Models for Therapeutic Applications of Transcranial Electrical Stimulation. <i>48th Annual Meeting of the International Neuropsychological Society</i>, February, 2020. </p>
<p class="style3"><span class="style35">[JOSA A'20]</span> Robledo EA, Schutzman R, Fang R, Fernandez C, Kwasinski R, Leiva K, Perez-Clavijo F, Godavarty A: Physiological wound assessment from coregistered and segmented tissue hemoglobin maps. <i>Journal of the Optical Society of America A</i> 2020 Aug 1;37(8):1249-56. <a href="https://www.osapublishing.org/josaa/abstract.cfm?uri=josaa-37-8-1249">DOI:10.1364/JOSAA.394985</a></p>
<p class="style3"><span class="style35">[MIA'20]</span> Stolte S*, Fang R: A Survey on Medical Image Analysis in Diabetic Retinopathy. <i>Medical Image Analysis</i> 2020 May 30:101742. <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841520301067">DOI:10.1016/j.media.2020.101742</a></p>
<p class="style3"><span class="style35">[MIA'20]</span> Porwal P, Pachade S, Kokare M, Deshmukh G, Son J, Bae W, Liu L, Wang J, Liu X, Gao L, Wu T. IDRiD: Diabetic Retinopathy-Segmentation and Grading Challenge. <i>Medical Image Analysis</i>. 2020 Jan 1;59:101561. <a href="10.1016/j.media.2019.101561">DOI:10.1016/j.media.2019.101561</a></p>
<p class="style3"><span class="style35">[RSNA'20]</span> Maximillian Diaz*, Jianqiao Tian*, Ruogu Fang: Machine Learning for Parkinsons Disease Diagnosis Using Fundus Eye Images, <i>Annual Meeting of Radiology Society of North America</i>, December, 2020. <span class="style38">Featured by Forbes and 30+ Media</p>
<p class="style3"><span class="style35">[SIIM'20]</span> Yao Xiao*, Manuel M. Arreola, Izabella Barreto, Wesley E. Bolch, W. Christopher Fox, Keith Peters, Dhanashree A. Rajderkar, John H. Rees, and Ruogu Fang: Multi-Series CT Image Super-Resolution by using Transfer Generative Adversarial Network, in <i>Society for Imaging Informatics in Medicine (SIIM) Annual Meeting</i> Austin, Texas, June 24-26, 2020 (Oral)</p>
<p class="style3"><span class="style35">[ISBI'20]</span> Yao Xiao*, Keith R. Peters, W. Christopher Fox, John H. Rees, Dhanashree A. Rajderkar, Manuel M. Arreola, Izabella Barreto, Wesley E. Bolch, and Ruogu Fang: Transfer-GAN: Multimodal CT Image Super-Resolution via Transfer Generative Adversarial Networks, in <i>IEEE International Symposium on Biomedical Imaging (ISBI)</i>, Iowa City, Iowa, April 3-7, 2020. <span class="style38">Travel Awards funded by US National Institutes of Health (NIH), National Institute of Biomedical Imaging and Bioengineering (NIBIB), National Cancer Institute (NCI), and Graduate Student Council.</span></p>
<p class="style3"><span class="style35">[SPIE Medical Imaging'20]</span> Yao Xiao*, Ruogu Fang: Transfer Generative Adversarial Network for Multimodal CT Image Super-Resolution, in <i>SPIE Medical Imaging</i>, Houston, Texas, Feb 15-20, 2020 (Oral Presentation), Proc. SPIE 11313, Medical Imaging 2020: Image Processing, 1131306 (17 March 2020) <a href="https://doi.org/10.1117/12.2549533">[pdf]</a></p>
<p class="style3"><span class="style35">[INS'20]</span> Albizu A, Indahlastari A, Nissim NR, OShea A, Fang R, Woods AJ: Building Personalized Medicinee Medicine Models for Therapeutic Applications of Transcranial Electrical Stimulation, in the <i>48th Annual Meeting of the International Neuropsychological Society</i> in February 2020</p>
<p class="style3"><span class="style35">[SNAMC'20]</span> Justin L Brown, Daniel El Basha*, Nathalie Correa, Yao Xiao*, Izabella Barreto, Ruogu Fang, Chan Kim, Wesley E. Bolch: Monte Carlo Dosimetry For CT Brain Perfusion Studies Utilizing Volumetric Acquisitions, in <i>Joint International Conference on Supercomputing in Nuclear Applications + Monte Carlo</i>, May 18-22, 2020.</p>
<p class="style3"><span class="style35">[ASCPT'20]</span> Marwa Tantawy, Sonal Singh, Guang Yang, Matt Gitzendanner, Yiqing Chen, Yonghui Wu, Ruogu Fang, William Hogan, Yan Gong: ZMAT4 and DOCK9 Variants Associated with Heart Failure in Breast Cancer Patients in the UK Biobank data, in <i>American Society for Clinical Pharmacology and Therapeutics Annual Meeting </i> in Houston, TX, March 18-21, 2020. Presidential Trainee Award, 2020 David J. Goldstein Trainee Award (This award is presented each year to recognize the highest scoring trainee abstract.).</p>
<p class="style3"><span class="style35">[MIA'20]</span> Prasanna Porwal, Samiksha Pachade, Manesh Kokare, Girish Deshmukh, Jaemin Son, Woong Bae, Lihong Liu, Jianzong Wang, Xinhui Liu, Liangxin Gao, TianBo Wu, Jing Xiao, Fengyan Wang, Baocai Yin, Yunzhi Wang, Gopichandh Danala, Linsheng He, Yoon Ho Choi, Yeong Chan Lee, Sang-Hyuk Jung, Zhongyu Li, Xiaodan Sui, Junyan Wu, Xiaolong Li, Ting Zhou, Janos Toth, Agnes Baran, Avinash Kori, Sai Saketh Chennamsetty, Mohammed Safwan, Varghese Alex, Xingzheng Lyu, Li Cheng,D, Qinhao Chu, Pengcheng Li, Xin Ji, Sanyuan Zhang, Yaxin Shen, Ling Dai, Oindrila Saha, Rachana Sathish, Tania Melo, Teresa Araujo, Balazs Harangi, Bin Sheng, Ruogu Fang, Debdoot Sheet, Andras Hajdu, Yuanjie Zheng, Ana Maria Mendonca, Shaoting Zhang, Aurelio Campilho, Bin Zheng, Dinggang Shen, Luca Giancardo, Gwenole Quellec, Fabrice Meriaudeau: IDRiD: Diabetic Retinopathy Segmentation and Grading Challenge, in Medical Image Analysis, vol. 59, 2020. (First Place in the International Diabetic Retinopathy Grading and Segmentation Challenge) <a href="https://www.sciencedirect.com/science/article/pii/S1361841519301033?dgcid=coauthor">[pdf]</a></p>
<p class="style3"><span class="style35">[MIA'20]</span> Jose Ignacio Orlando, Huazhu Fu, Joao Barbossa Breda, Karel van Keer, Deepti R. Bathula, Andres Diaz-Pinto, Ruogu Fang, Pheng-Ann Heng, Jeyoung Kim, JoonHo Lee, Joonseok Lee, Xiaoxiao Li, Peng Liu*, Shuai Lu, Balamurali Murugesan, Valery Naranjo, Sai Samarth R. Phaye, Sharath M. Shankaranarayana, Apoorva Sikka, Jaemin Son, Anton van den Hengel, Shujun Wang, Junyan Wu, Zifeng Wu, Guanghui Xu, Yongli Xu, Pengshuai Yin, Fei Li, Xiulan Zhang, Yanwu Xu, Hrvoje Bogunovic : REFUGE Challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs, in <i>Medical Image Analysis, vol. 59</i>, 2020. <a href="https://doi.org/10.1016/j.media.2019.101570">[pdf]</a></p>
<p class="style3"><span class="style35">[MICCAI'19]</span> Peng Liu*, Bin Kong, Zhongyu Li, Shaoting Zhang, Ruogu Fang: CFEA: Collaborative Feature Ensembling Adaptation for Domain Adaptation in Unsupervised Optic Disc and Cup Segmentation, in <i>Medical Image Analysis and Computer Assisted Intervention</i>, October, 2019. (Early Acceptance Rate = 10%-15%) </p>
<p class="style3"><span class="style35">[RSNA'19]</span> Yao Xiao*, Manual Arreola, Izabella Barreto, W. Christopher Fox, Keith Peters, Ruogu Fang: Multimodal CT Image Super-Resolution via Transfer Generative Adversarial Network, in <i>Annual Meeting of Radiology Society of North American</i>, December 2019. (Oral presentation)</p>
<p class="style3"><span class="style35">[BMES'19]</span> Yao Xiao*, Ruogu Fang: Multimodal CT Image Super-Resolution via Transfer-GAN, in <i>Biomedical Engineering Society Annual Meeting</i>, October, 2019, Philadelphia, PA.</p>
<p class="style3"><span class="style35">[BMES'19]</span> Jianqiao Tian*, Max Diaz*, Ruogu Fang: Deep Learning-based Alzheimer's Disease Classification of FDG-PET and AV45 PET Images, in <i>Biomedical Engineering Society Annual Meeting</i>, October, 2019, Philadelphia, PA.</p>
<p class="style3"><span class="style35">[BMES'19]</span> Skylar Stolte*, Ruogu Fang: Artificial Intelligence For Automated Diagnosis of Glaucoma in Stereoscopic Images, in <i>Biomedical Engineering Society Annual Meeting</i>, October, 2019, Philadelphia, PA.</p>
<p class="style3"><span class="style35">[BMES'19]</span> Kyle See*, Ruogu Fang: Classification of Neural Stimulations In The Brain With Super Voxels, in <i>Biomedical Engineering Society Annual Meeting</i>, October, 2019, Philadelphia, PA.</p>
<p class="style3"><span class="style35">[BMES'19]</span> Skylar Stolte*, Kyle See*, Daniel El Basha*, Ruogu Fang: Retinal Disease Diagnosis Using Mobile Devices, in <i>Biomedical Engineering Society Annual Meeting</i>, October, 2019, Philadelphia, PA.</p>
<p class="style3">	* indicates students mentored by the PIs</p>

<!--Patents-->
<h3>Patents</h3>
<p class="style3">1. Neural Network Evolution Using Expedited Genetic Algorithm for Medical Image Denoising. Inventors: <b>Ruogu Fang</b>, Peng Liu. Ref. No: UF#17344, Filed on 9/3/2019, will be published on March 12, 2020. U.S. Utility Patent Application Serial No. 16/558,779</p>
<p class="style3">2. T17996UF001 "Multimodal CT Image Super-Resolution Via Transfer Generative Adversarial Network" <b>Ruogu Fang</b>, Yao Xiao, Provisional Patent Filed on March 25, 2020.</p>

<!--Dissertation-->
<h3>Dissertations</h3>
<p class="style3">Deep Learning for Multimodal CT Image Quality Enhancement and Radiation Exposure Optimization, Yao Xiao, University of Florida, 2020</p>

<!--Students-->
<h3>Students</h3>
<p class="style33">Graduated PhD: Yao Xiao (UF) BMES Career Developmental Award, Graduate Student Speaker at College of Engineering Commencement 2020, Post-doc at MD Anderson</p>
<p class="style33">Graduate: Peng Liu (UF), Skylar Stolte (UF)</p>
<p class="style33">Undergraduate: Garrett Fullterton, Simon Kato</p>

<!--Classes related to the project-->
<h3>Classes related to the project</h3>
<p class="style38"><u>Fall 2020</u>: BME3053C Computer Applications for BME</p>
<p class="style38"><u>Fall 2019</u>: BME3053C Computer Applications for BME</p>

<!--Collaboration Events-->
<h3>Collaboration Events</h3>
<p class="style56"}>Weekly in-person or online meetings from 2019-2022</p>


<span style="mso-bidi-font-weight: bold"><st1:City w:st="on"><st1:PlaceName w:st="on"></st1:PlaceName></st1:City></span>Last modified: 09/2020
</body>
</html>